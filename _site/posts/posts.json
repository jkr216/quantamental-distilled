[
  {
    "path": "posts/2020-09-11-backtesting-strategies/",
    "title": "Backtesting Strategies",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Jonathan K. Regenstein",
        "url": "https://fintech.gatech.edu/#/people"
      },
      {
        "name": "Sudheer Chava",
        "url": "https://fintech.gatech.edu/#/people"
      }
    ],
    "date": "2020-09-11",
    "categories": [],
    "contents": "\n\n# A tibble: 6 x 14\n  ticker date                close  high   low  open volume adjClose\n  <chr>  <dttm>              <dbl> <dbl> <dbl> <dbl>  <int>    <dbl>\n1 VFINX  1990-01-02 00:00:00  34.2  34.2  34.2  34.2      0     17.9\n2 VFINX  1990-01-03 00:00:00  34.2  34.2  34.2  34.2      0     17.9\n3 VFINX  1990-01-04 00:00:00  33.9  33.9  33.9  33.9      0     17.7\n4 VFINX  1990-01-05 00:00:00  33.5  33.5  33.5  33.5      0     17.6\n5 VFINX  1990-01-08 00:00:00  33.7  33.7  33.7  33.7      0     17.7\n6 VFINX  1990-01-09 00:00:00  33.3  33.3  33.3  33.3      0     17.4\n# … with 6 more variables: adjHigh <dbl>, adjLow <dbl>,\n#   adjOpen <dbl>, adjVolume <int>, divCash <dbl>, splitFactor <dbl>\n\n\n# A tibble: 6 x 8\n  ticker date       close daily_return sma_50[,1] sma_200[,1] signal\n  <chr>  <date>     <dbl>        <dbl>      <dbl>       <dbl>  <dbl>\n1 VFINX  2020-11-19  331.      0.00400       316.        291.      1\n2 VFINX  2020-11-20  329.     -0.00679       317.        291.      1\n3 VFINX  2020-11-23  331.      0.00574       317.        291.      1\n4 VFINX  2020-11-24  336.      0.0162        317.        291.      1\n5 VFINX  2020-11-25  336.     -0.00155       318.        291.      1\n6 VFINX  2020-11-27  337.      0.00247       318.        291.      1\n# … with 1 more variable: position <dbl>\n\n\n# A tibble: 7,590 x 10\n   ticker date       close close_roll_25 close_roll_50 close_roll_100\n   <chr>  <date>     <dbl>         <dbl>         <dbl>          <dbl>\n 1 VFINX  1990-10-15  29.1          29.8          30.6           32.5\n 2 VFINX  1990-10-16  28.7          29.8          30.5           32.5\n 3 VFINX  1990-10-17  28.7          29.7          30.5           32.4\n 4 VFINX  1990-10-18  29.3          29.6          30.4           32.4\n 5 VFINX  1990-10-19  30.0          29.6          30.4           32.3\n 6 VFINX  1990-10-22  30.2          29.6          30.3           32.3\n 7 VFINX  1990-10-23  30.0          29.5          30.3           32.2\n 8 VFINX  1990-10-24  30            29.5          30.2           32.2\n 9 VFINX  1990-10-25  29.8          29.5          30.2           32.1\n10 VFINX  1990-10-26  29.2          29.5          30.1           32.1\n# … with 7,580 more rows, and 4 more variables: close_roll_200 <dbl>,\n#   daily_return <dbl>, signal <dbl>, position <dbl>\n\n\n\n\n",
    "preview": {},
    "last_modified": "2020-11-30T22:42:12-05:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-08-21-from-raw-fundies-to-ratios/",
    "title": "From Raw Fundies to Ratios",
    "description": "A short description of the post.",
    "author": [
      {
        "name": "Jonathan K. Regenstein",
        "url": "https://fintech.gatech.edu/#/people"
      },
      {
        "name": "Sudheer Chava",
        "url": "https://fintech.gatech.edu/#/people"
      }
    ],
    "date": "2020-08-21",
    "categories": [
      "quantamental",
      "financial ratios"
    ],
    "contents": "\nTable of Contents\nImporting the Data\nConvert to Ratios\nImporting the Data\nWe start as always with importing the 2019 financial statements for Apple and joining it with the data definitions. We covered this process extensively in this post and the full code is below.\n\n\naapl_financial_statements <- \n  GET(\n  url = str_glue(\n    \"https://api.tiingo.com/tiingo/fundamentals/aapl/statements?format=csv&\n    startDate=2018-01-01&endDate=2020-01-31&token={api_key}\"\n  )) %>%\n  content(as = \"parsed\")  %>% \n  left_join(definitions)\n\nWe can isolate the annual statement with filter(quarter == 0).\n\n\naapl_2019_annual_statements <- \naapl_financial_statements %>% \n  filter(quarter == 0)\n\nWe now have an object called aapl_2019_annual_statements that holds the 2019 Balance Sheet, Income Statement and Cash Flow Statement for Apple. We can think of this as the raw data reported by the company. As we saw in previous post (like this one), that raw data is important for evaluating the health and value of a company. That process of turning raw data into valuations is the essence of fundamental research.\nHowever, those items of raw data can also be combined to form ratios that are informative and instructive. In the followinng section we will convert well formatted, tidy financial statements into some key ratios but before we do so, a brief aside on the data science perspective.\nThe use of ratios like the Quick Ratio or the Debt Ratio has been part of fundamental research for a long time and it doesn’t seem particularly fancy. From a data science perspective, when we form ratios, we are taking multiple pieces of raw data and combining them together in order to find a more informative piece of data. We can think of this as a flavor of ‘feature engineering’, which can be defined as “adjusting and reworking predictors to enable models to better uncover predictor-response relationships.”1 Feature engineering is part of the machine learning process, which is separate from fundmantal analysis. Converting financial statement items to ratios is not feature engineering, but it’s a similar idea: we are searching for ways to adjust and rework our data to give us better insights into the future valuation of a company.\n[JKR Note: needs more]\nConvert to Ratios\nLet’s calculate a few ratios, the effective tax rate, net working capital and free cash flow. Note that free cash flow is a function of both effective tax rate and net working capital, so we will calculate effective tax rate and net working capital first, then use them to find free cash flow.\nWe will use summarise() for this work.\n\n\naapl_2019_annual_statements %>% \n  select(date, year, quarter, dataCode, value) %>% \npivot_wider(names_from = \"dataCode\", values_from = \"value\") %>% \n  group_by(date, year, quarter) %>% \n  summarise(eff_tax_rate = taxExp/ ebt,\n    net_working_capital = assetsCurrent- liabilitiesCurrent,\n    FCF = (ebit* (1 - eff_tax_rate)) + depamor + net_working_capital - capex,\n    ROA = netinc/ totalAssets,\n    debt_ratio = totalLiabilities / totalAssets,\n    work_cap_assets_ratio = (assetsCurrent - liabilitiesCurrent ) / totalAssets,\n    quick_ratio = (cashAndEq + acctRec - investmentsCurrent ) / liabilitiesCurrent,\n    retained_earnings_assets_ratio = retainedEarnings / totalAssets) %>% \n  pivot_longer(eff_tax_rate:retained_earnings_assets_ratio) %>% \n    mutate(dataCode = name, \n           name = c(\n             \"effective tax rate\",\n             \"net working capital\",\n             \"free cash flow\",\n             \"return on assets\",\n             \"debt ratio\",\n             \"working capital ratio\",\n             \"quick ratio\",\n             \"retained earnings assets ratio\"\n           ),\n           units = \"$\",\n           statementType = \"ratios\")\n\n# A tibble: 16 x 8\n# Groups:   date, year [2]\n   date        year quarter name     value dataCode units\n   <date>     <dbl>   <dbl> <chr>    <dbl> <chr>    <chr>\n 1 2018-09-29  2018       0 effe… 1.83e- 1 eff_tax… $    \n 2 2018-09-29  2018       0 net … 1.54e+10 net_wor… $    \n 3 2018-09-29  2018       0 free… 9.92e+10 FCF      $    \n 4 2018-09-29  2018       0 retu… 1.63e- 1 ROA      $    \n 5 2018-09-29  2018       0 debt… 7.07e- 1 debt_ra… $    \n 6 2018-09-29  2018       0 work… 4.21e- 2 work_ca… $    \n 7 2018-09-29  2018       0 quic… 2.98e- 1 quick_r… $    \n 8 2018-09-29  2018       0 reta… 1.92e- 1 retaine… $    \n 9 2019-09-28  2019       0 effe… 1.59e- 1 eff_tax… $    \n10 2019-09-28  2019       0 net … 5.71e+10 net_wor… $    \n11 2019-09-28  2019       0 free… 1.35e+11 FCF      $    \n12 2019-09-28  2019       0 retu… 1.63e- 1 ROA      $    \n13 2019-09-28  2019       0 debt… 7.33e- 1 debt_ra… $    \n14 2019-09-28  2019       0 work… 1.69e- 1 work_ca… $    \n15 2019-09-28  2019       0 quic… 4.06e- 1 quick_r… $    \n16 2019-09-28  2019       0 reta… 1.36e- 1 retaine… $    \n# … with 1 more variable: statementType <chr>\n\nfeat.engineering↩\n",
    "preview": "posts/2020-08-21-from-raw-fundies-to-ratios/ratios.png",
    "last_modified": "2020-08-21T09:46:50-04:00",
    "input_file": {},
    "preview_width": 1432,
    "preview_height": 478
  },
  {
    "path": "posts/2020-08-19-getting-functional-for-cogs/",
    "title": "Getting Functional for COGS",
    "description": "A short article on creating a function to calculate COGS.",
    "author": [
      {
        "name": "Jonathan K. Regenstein",
        "url": "https://fintech.gatech.edu/#/people"
      },
      {
        "name": "Sudheer Chava",
        "url": "https://fintech.gatech.edu/#/people"
      }
    ],
    "date": "2020-08-19",
    "categories": [],
    "contents": "\nTable of Contents\nDefinitions\nCOGS Code\nIn this post, we will walk through the construction of a function to calculate the Cost of Goods Sold (COGS) based on the Revenue and Goss Profit reported in a financial statement. Often COGS is a separate Income Statement item but it is not one reported in Tiingo fundamental data.\nWe covered the Tiingo fundamentals API in detail in this post but by way of quick refresher, the following Income Statement fields are reported.\nDefinitions\nLet’s first review the definitions for each of the data codes in the Income Statement.\n\n\ndefinitions <-\n  httr::GET(\n    url = str_glue(\"https://api.tiingo.com/tiingo/fundamentals/definitions?format=csv&token={api_key}\")\n    ) %>%\n  content(as = \"parsed\")  %>%\n  select(statementType, everything()) %>%\n  arrange(statementType) \n\ndefinitions %>% \n  filter(statementType == \"incomeStatement\")\n\n# A tibble: 22 x 5\n   statementType  dataCode    name         description           units\n   <chr>          <chr>       <chr>        <chr>                 <chr>\n 1 incomeStateme… revenue     Revenue      Revenue               $    \n 2 incomeStateme… epsDil      Earnings Pe… EPS for diluted shar… $    \n 3 incomeStateme… netinc      Net Income   Net income            $    \n 4 incomeStateme… shareswaDil Weighted Av… Used to calculated d… <NA> \n 5 incomeStateme… eps         Earnings Pe… Earnings per basic s… $    \n 6 incomeStateme… ebitda      EBITDA       EBITDA is a non-GAAP… $    \n 7 incomeStateme… rnd         Research & … The aggregate costs … $    \n 8 incomeStateme… sga         Selling, Ge… The aggregate total … $    \n 9 incomeStateme… opinc       Operating I… Operating income is … $    \n10 incomeStateme… nonControl… Net Income … The portion of incom… $    \n# … with 12 more rows\n\nNo mention of COGS, which gives us an opportunity to build a custom function for the job. If you’re new to the world of R programming, that might seem like a huge task - building a custom function! Well, maybe that doesn’t seem intimidating to you but when I was starting with R programming it seemed intimidating to me. The motivation behind function building is to save ourselves (and possibly our collaborators, or any R coder with whom we share our work) from having to copy paste lines and lines of code each time we want to perform a certain task. If we want to bundle up a bunch of functions and share them, that becomes a package. For example, when we use the dplyr package to select() a column, we using a function from the package.\nWe will approach this task from a utilitarian perspective, in the sense that we wish to build a function that accomplish our task and saves us time. We are not thinking from the perspective of a hard core package developer who might consider how a function scales, or how fast it runs on huge data sets, or how easy it is for random end users to consume. That stuff is important but first we want to get comfortable building functions for ourselves that accomplish the task at hand. Let’s get to it.\nCOGS Code\nWe will start by calculating COGS without a function, but first we import financial statement data. We covered this extensively in this post and here is the code.\n\n\n\n\n\naapl_financial_statements <- \n  GET(\n  url = str_glue(\n    \"https://api.tiingo.com/tiingo/fundamentals/aapl/statements?format=csv&\n    startDate=2018-01-01&endDate=2020-01-31&token={api_key}\"\n  )) %>%\n  content(as = \"parsed\")  %>% \n  left_join(definitions)\n\nWe just imported all of the financial statements for Apple from 2018 to beginning of 2020. Let’s filter() down to just the 10K Income Statement for 2019. We get the 10K by setting filter(quarter == 0), which indicates we want the annual report.\n\n\naapl_2019_annual_is <-  \n  aapl_financial_statements %>% \n  filter(statementType == \"incomeStatement\",\n         year == 2019,\n         quarter == 0)\n\nNext, we want to calculate COGS, which is the difference between Revenue and Gross Profit. Let’s filter down to those two entries.\n\n\naapl_2019_annual_is %>% \nfilter(dataCode %in% c(\"revenue\", \"grossProfit\")) \n\n# A tibble: 2 x 9\n  date        year quarter statementType dataCode   value name \n  <date>     <dbl>   <dbl> <chr>         <chr>      <dbl> <chr>\n1 2019-09-28  2019       0 incomeStatem… revenue  2.60e11 Reve…\n2 2019-09-28  2019       0 incomeStatem… grossPr… 9.84e10 Gros…\n# … with 2 more variables: description <chr>, units <chr>\n\nWe want COGS as of a certain date, so let’s group_by(date) and then select() just our columns of interest.\n\n\naapl_2019_annual_is %>% \nfilter(dataCode %in% c(\"revenue\", \"grossProfit\"))  %>% \n  group_by(date) %>% \n    select(date, dataCode, value)\n\n# A tibble: 2 x 3\n# Groups:   date [1]\n  date       dataCode           value\n  <date>     <chr>              <dbl>\n1 2019-09-28 revenue     260174000000\n2 2019-09-28 grossProfit  98392000000\n\nNow we want the difference between revenue and grossProfit. That will be easier to accomplish if we pivot_wider() this data first and create two columns for the data.\n\n\naapl_2019_annual_is %>% \nfilter(dataCode %in% c(\"revenue\", \"grossProfit\"))  %>% \n  group_by(date) %>% \n    select(date, dataCode, value) %>% \n  pivot_wider(names_from = \"dataCode\", values_from = \"value\") \n\n# A tibble: 1 x 3\n# Groups:   date [1]\n  date            revenue grossProfit\n  <date>            <dbl>       <dbl>\n1 2019-09-28 260174000000 98392000000\n\nFrom here, we subtract grossProfit from revenue, inside of a call to summarise().\n\n\naapl_2019_annual_is %>% \nfilter(dataCode %in% c(\"revenue\", \"grossProfit\"))  %>% \n  group_by(date) %>% \n    select(date, dataCode, value) %>% \n  pivot_wider(names_from = \"dataCode\", values_from = \"value\") %>% \n   summarise(cogs = revenue - grossProfit)\n\n# A tibble: 1 x 2\n  date               cogs\n  <date>            <dbl>\n1 2019-09-28 161782000000\n\nWe eventually want to bind this data to our original Income Statement and thus we want to match the existing columns in aapl_2019_annual_is.\n\n\naapl_2019_annual_is %>% \nfilter(dataCode %in% c(\"revenue\", \"grossProfit\"))  %>% \n  group_by(date) %>% \n    select(date, dataCode, value) %>% \n  pivot_wider(names_from = \"dataCode\", values_from = \"value\") %>% \n   summarise(value  = revenue - grossProfit)  %>% \n    mutate(dataCode = \"cogs\", \n           name = \"Cost of Goods Sold\",\n           units = \"$\",\n           statementType = \"incomeStatement\")\n\n# A tibble: 1 x 6\n  date             value dataCode name            units statementType \n  <date>           <dbl> <chr>    <chr>           <chr> <chr>         \n1 2019-09-28     1.62e11 cogs     Cost of Goods … $     incomeStateme…\n\nPutting it all together, with a final call to bind_rows().\n\n\ncogs <- \n  aapl_2019_annual_is %>% \nfilter(dataCode %in% c(\"revenue\", \"grossProfit\"))  %>% \n  group_by(date) %>% \n    select(date, dataCode, value) %>% \n  pivot_wider(names_from = \"dataCode\", values_from = \"value\") %>% \n   summarise(value  = revenue - grossProfit)  %>% \n    mutate(dataCode = \"cogs\", \n           name = \"Cost of Goods Sold\",\n           units = \"$\",\n           statementType = \"incomeStatement\",\n           year = 2019, \n           quarter = 0)\n\n\naapl_2019_annual_is %>% \n  bind_rows(cogs) %>% \n  tail()\n\n# A tibble: 6 x 9\n  date        year quarter statementType dataCode   value name \n  <date>     <dbl>   <dbl> <chr>         <chr>      <dbl> <chr>\n1 2019-09-28  2019       0 incomeStatem… ebitda   7.83e10 EBIT…\n2 2019-09-28  2019       0 incomeStatem… epsDil   1.19e 1 Earn…\n3 2019-09-28  2019       0 incomeStatem… opex     3.45e10 Oper…\n4 2019-09-28  2019       0 incomeStatem… costRev  1.62e11 Cost…\n5 2019-09-28  2019       0 incomeStatem… consoli… 5.53e10 Cons…\n6 2019-09-28  2019       0 incomeStatem… cogs     1.62e11 Cost…\n# … with 2 more variables: description <chr>, units <chr>\n\nWe have now calculated and added COGS to the Income Statement. It would be nice to be able to repeat process, without having to rewrite all that code. Have a close look at the chunk above and notice that it should work well on any Income Statetement that we import and wrangle from Tiingo. That is, we should be able to pass another Income Statement object into that same code flow. If that’s so, we can create a function that accepts an Income Statement object and returns the cogs. Here’s what that might look like:\n\n\ncogs_get_funs <- function(income_statement){\n  income_statement %>% \n    filter(dataCode %in% c(\"revenue\", \"grossProfit\")) %>% \n    group_by(date) %>% \n    select(date, dataCode, value) %>% \n    pivot_wider(names_from = \"dataCode\", values_from = \"value\") %>% \n    summarise(value = revenue - grossProfit) %>% \n    mutate(dataCode = \"cogs\", \n           name = \"Cost of Goods Sold\",\n           units = \"$\",\n           statementType = \"incomeStatement\")\n}\n\nLet’s see what happens when pass aapl_2019_annual_is to that function.\n\n\naapl_2019_annual_is %>% \n  cogs_get_funs()\n\n# A tibble: 1 x 6\n  date             value dataCode name            units statementType \n  <date>           <dbl> <chr>    <chr>           <chr> <chr>         \n1 2019-09-28     1.62e11 cogs     Cost of Goods … $     incomeStateme…\n\nE voila! We did a lot of work to get that code flow just how we want it, but now we can efficiently pass any Income Statement to that function. How about putting bind_rows() into the same flow?\n\n\naapl_2019_annual_is %>% \n  bind_rows(\n    cogs_get_funs(.)\n  ) %>% \n  tail()\n\n# A tibble: 6 x 9\n  date        year quarter statementType dataCode   value name \n  <date>     <dbl>   <dbl> <chr>         <chr>      <dbl> <chr>\n1 2019-09-28  2019       0 incomeStatem… ebitda   7.83e10 EBIT…\n2 2019-09-28  2019       0 incomeStatem… epsDil   1.19e 1 Earn…\n3 2019-09-28  2019       0 incomeStatem… opex     3.45e10 Oper…\n4 2019-09-28  2019       0 incomeStatem… costRev  1.62e11 Cost…\n5 2019-09-28  2019       0 incomeStatem… consoli… 5.53e10 Cons…\n6 2019-09-28    NA      NA incomeStatem… cogs     1.62e11 Cost…\n# … with 2 more variables: description <chr>, units <chr>\n\nE double voila! We start with out object aapl_2019_annual_is, pipe it to bind_rows() and inside of bind_rows() we call cogs_get_funs(.). That . in the parentheses tell our function to operate on the object aapl_2019_annual_is.\n\n\n",
    "preview": "posts/2020-08-19-getting-functional-for-cogs/cogs-funs.png",
    "last_modified": "2020-08-21T09:46:16-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-08-18-quanta-versus-funda-mental/",
    "title": "Quanta versus Funda Mental",
    "description": "A quick introduction to what mean by quantamental.",
    "author": [
      {
        "name": "Jonathan K. Regenstein",
        "url": "https://fintech.gatech.edu/#/people"
      },
      {
        "name": "Sudheer Chava",
        "url": "https://fintech.gatech.edu/#/people"
      }
    ],
    "date": "2020-08-18",
    "categories": [
      "quantamental"
    ],
    "contents": "\nTable of Contents\nDefinitions\nImport Financials from Tiingo\nVisualize Income Statement\nWhat is quanta versus funda mental analysis?\nIn FM, items from financial statements are inputs to try to estimate a valuation. Almost universally, this involves updating values in a spreadsheet with a complicated link structure that ultimately generates a value for a company, which leads to a price target for an equity. If that price targe is above, the current price, the equity will usually be rated a ‘buy’, and so on. In QM, financial statement items can be treated in two ways. First, as features, or the basis for engineered features, that are used to model and predict the movement of an equity’s price. In other words, in FM, items are numeric inputs, that are entered into equations, and those equations generate a number. In QM, items are features that generate model results, which are used to estimate future outcomes.\nRelatedly, in QM, those financial statement items can themselves be the the variables of interest. We might be attempting to forecast or nowcast financial statement items, in order to forecast or nowcast price movements.\nIn FM, the relationship between financial statement items and the variable of interest, usually price, is not statistical, it’s the not the result of estimating model parameters. It’s the result of assumptions or calculations about the relationship between items and price. In QM, the relationships can be modeled or estimated using statistical learning or machine learning, which depends on larger data sets and generally longer history than FM.\nDefinitions\nLet’s first review the definitions for each of the data codes. We are accessing this data via an API and very often an API will supply a data dictionary similar to these definitions.\n\n\ndefinitions <- \n  httr::GET(\nurl = \n  str_glue(\"https://api.tiingo.com/tiingo/fundamentals/definitions?format=csv&token={api_key}\")\n    ) %>%\n  content(as = \"parsed\")  %>%\n  select(statementType, everything()) %>%\n  arrange(statementType)  \n\ndefinitions %>% \n  head() %>% \n  reactable()\n\n{\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"statementType\":[\"balanceSheet\",\"balanceSheet\",\"balanceSheet\",\"balanceSheet\",\"balanceSheet\",\"balanceSheet\"],\"dataCode\":[\"sharesBasic\",\"ppeq\",\"investmentsCurrent\",\"taxLiabilities\",\"assetsNonCurrent\",\"taxAssets\"],\"name\":[\"Shares Outstanding\",\"Property, Plant & Equipment\",\"Current Investments\",\"Tax Liabilities\",\"Other Assets\",\"Tax Assets\"],\"description\":[\"Outstanding shares\",\"A component of assets representing the total amount of marketable and non-marketable securties, loans receivable and other invested assets.\",\"The current portion of Investments, reported if the company operates a classified balance sheet that segments current and non-current assets.\",\"A component of liabilities representing outstanding tax liabilities.\",\"Assets that cannot be easily converted into cash and where the value of the item will be realized in a year\",\"A component of assets representing tax assets and receivables.\"],\"units\":[null,\"$\",\"$\",\"$\",\"$\",\"$\"]},\"columns\":[{\"accessor\":\"statementType\",\"name\":\"statementType\",\"type\":\"character\"},{\"accessor\":\"dataCode\",\"name\":\"dataCode\",\"type\":\"character\"},{\"accessor\":\"name\",\"name\":\"name\",\"type\":\"character\"},{\"accessor\":\"description\",\"name\":\"description\",\"type\":\"character\"},{\"accessor\":\"units\",\"name\":\"units\",\"type\":\"character\"}],\"defaultPageSize\":10,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"dataKey\":\"3e50b68bada4cbffe88ac8d71a141cac\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]}\nImport Financials from Tiingo\n\n\n\n\n\naapl_financial_statements <- \n  GET(\n  url = str_glue(\n    \"https://api.tiingo.com/tiingo/fundamentals/aapl/statements?format=csv&\n    startDate=2018-01-01&endDate=2020-01-31&token={api_key}\"\n  )) %>%\n  content(as = \"parsed\")  %>% \n  left_join(definitions)\n\nWe just imported all of the financial statements for Apple from 2018 to beginning of 2020. Let’s filter() down to just the 10K Income Statement for 2019. We get the 10K by setting filter(quarter == 0), which indicates we want the annual report.\n\n\naapl_2019_annual_is <-  \n  aapl_financial_statements %>% \n  filter(statementType == \"incomeStatement\",\n         year == 2019,\n         quarter == 0)\n\nTiingo does not include an entry for Cost of Goods Sold, or COGS. That’s a common item and we can calculate it from the difference between revenue and grossProfit items. We built a custom function to do this called cogs_get_funs() that we can pass an income statement to in order to get back the COGS.\nTo learn about how we constructed this function, have a look at this post.\n\n\n\n\n\ncogs_get_funs(aapl_2019_annual_is)\n\n# A tibble: 1 x 6\n  date             value dataCode name            units statementType \n  <date>           <dbl> <chr>    <chr>           <chr> <chr>         \n1 2019-09-28     1.62e11 cogs     Cost of Goods … $     incomeStateme…\n\nVisualize Income Statement\nLet’s use a waterfall chart to visualize the Income Statement and the way in which Revenue flows to Gross Profit after subtracting Cost of Goods sold, to Operating Income (or EBIT) after subtracting R&D and Selling, General and Admin costs, to EBT after subtracting Interest Expense, to Net Income, after subtracting Tax Expense. This style of chart is called a waterflow because numbers flow from the highest down to the lowest. We think it’s an intuitive way to visualize how an income statment goes from a top line number to a bottom line number.\n\n\naapl_2019_annual_is %>% \n  # select(-year, -quarter) %>% \n  bind_rows(cogs_get_funs(.)) %>% \n  filter(\n    dataCode %in% c(\"revenue\", \"cogs\", \"grossProfit\", \"rnd\", \"\n                    sga\", \"opinc\", \"intexp\", \"ebt\", \"taxExp\", \"netinc\"),\n    date == max(date)\n  ) %>% \n  arrange(value) %>% \n  mutate(\n    value = case_when(dataCode %in% c(\"cogs\", \"taxExp\", \n                                      \"intexp\", \"rnd\", \"sga\") ~ value * -1,\n                      TRUE ~ value),\n    measure = case_when(dataCode %in% c(\"grossProfit\", \"opinc\", \n                                        \"ebt\", \"netinc\") ~ \"total\",\n                        TRUE ~ \"relative\"),\n    dataCode = fct_relevel(\n      dataCode,\n      c(\"revenue\",\n        \"cogs\",\n        \"grossProfit\",\n        \"rnd\",\n        \"sga\",\n        \"opinc\",\n        \"intexp\",\n        \"ebt\",\n        \"taxExp\",\n        \"netinc\"\n        )\n    ),\n    name = fct_relevel(\n      name,\n      c(\"Revenue\",\n        \"Cost of Goods Sold\",\n        \"Gross Profit\",\n        \"Research and Development\",\n        \"Selling, General and Administrative\",\n        \"Operating Income\",\n        \"Interest Expence\",\n        \"Earnings before tax\",\n        \"Tax Expense\",\n        \"Net Income\"\n        )\n    )\n  ) %>% \n  arrange(dataCode) %>% \n  select(dataCode, value, measure, name) %>% \n  plot_ly(name = \"Income Statement\", type = \"waterfall\", measure = ~measure, \n  x = ~dataCode, textposition = \"outside\", y= ~value,\n  text = ~str_glue(\"{name}\n                   ${scales::label_number_si(accuracy = 0.1)(value)}\"),\n  hoverinfo = 'text',\n  showlegend = F\n  ) %>%\n  # connector = list(line = list(color= \"rgb(63, 63, 63)\"))) %>%\n  layout(title = str_glue(\"Income statement 2019\"),\n        xaxis = list(title = \"\"),\n        yaxis = list(title = \"\",\n                     tickprefix = \"$\"),\n        autosize = TRUE,\n        showlegend = TRUE)\n\n{\"x\":{\"visdat\":{\"11ef2ae0f9f4\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"11ef2ae0f9f4\",\"attrs\":{\"11ef2ae0f9f4\":{\"measure\":{},\"x\":{},\"textposition\":\"outside\",\"y\":{},\"text\":{},\"hoverinfo\":\"text\",\"showlegend\":false,\"name\":\"Income Statement\",\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"waterfall\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"title\":\"Income statement 2019\",\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"\",\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"revenue\",\"cogs\",\"grossProfit\",\"rnd\",\"opinc\",\"intexp\",\"ebt\",\"taxExp\",\"netinc\"]},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"\",\"tickprefix\":\"$\"},\"autosize\":true,\"showlegend\":true,\"hovermode\":\"closest\"},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"measure\":[\"relative\",\"relative\",\"total\",\"relative\",\"total\",\"relative\",\"total\",\"relative\",\"total\"],\"x\":[\"revenue\",\"cogs\",\"grossProfit\",\"rnd\",\"opinc\",\"intexp\",\"ebt\",\"taxExp\",\"netinc\"],\"textposition\":[\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\"],\"y\":[260174000000,-161782000000,98392000000,-16217000000,63930000000,-0,65737000000,-10481000000,55256000000],\"text\":[\"Revenue<br />$260.2B\",\"Cost of Goods Sold<br />$-161.8B\",\"Gross Profit<br />$98.4B\",\"Research & Development<br />$-16.2B\",\"Operating Income<br />$63.9B\",\"Interest Expense<br />$0.0\",\"Earnings before tax<br />$65.7B\",\"Tax Expense<br />$-10.5B\",\"Net Income<br />$55.3B\"],\"hoverinfo\":[\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\"],\"showlegend\":false,\"name\":\"Income Statement\",\"type\":\"waterfall\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\nWe start with Revenue, and subtract COGS to get Gross Profit. We then subtract Research and Development Costs, and Selling, General and Adminstrative Costs to get Operating Income (or EBIT). From there, we move to EBT and finally Net Income.\nSimilar to what we did with the COGS function, we can wrap this entire process into a function that returns a chart, instead of returning a number or a data frame.\n\n\nincome_statement_waterfall_charter <- function(income_statement, ticker_for_title){\n  income_statement %>% \n  # select(-year, -quarter) %>% \n  bind_rows(cogs_get_funs(.)) %>% \n  filter(\n    dataCode %in% c(\"revenue\", \"cogs\", \"grossProfit\", \"rnd\", \"sga\", \n                    \"opinc\", \"intexp\", \"ebt\", \"taxExp\", \"netinc\"),\n    date == max(date)\n  ) %>% \n  arrange(value) %>% \n  mutate(\n    value = case_when(dataCode %in% c(\"cogs\", \"taxExp\", \"intexp\", \n                                      \"rnd\", \"sga\") ~ value * -1,\n                      TRUE ~ value),\n    measure = case_when(dataCode %in% c(\"grossProfit\", \"opinc\", \n                                        \"ebt\", \"netinc\") ~ \"total\",\n                        TRUE ~ \"relative\"),\n    dataCode = fct_relevel(\n      dataCode,\n      c(\"revenue\", \n        \"cogs\",\n        \"grossProfit\",\n        \"rnd\",\n        \"sga\",\n        \"opinc\",\n        \"intexp\",\n        \"ebt\",\n        \"taxExp\",\n        \"netinc\"\n        )\n    ),\n    name = fct_relevel(\n      name,\n      c(\"Revenue\",\n        \"Cost of Goods Sold\",\n        \"Gross Profit\",\n        \"Research and Development\",\n        \"Selling, General and Administrative\",\n        \"Operating Income\",\n        \"Interest Expence\",\n        \"Earnings before tax\",\n        \"Tax Expense\",\n        \"Net Income\"\n        )\n    )\n  ) %>% \n  arrange(dataCode) %>% \n  select(dataCode, value, measure, name) %>% \n  plot_ly(name = \"Income Statement\", type = \"waterfall\", measure = ~measure,\n  x = ~dataCode, textposition = \"outside\", y = ~value, \n  text = ~str_glue(\"{name}\n                   ${scales::label_number_si(accuracy = 0.1)(value)}\"),\n  hoverinfo = 'text',\n  showlegend = F\n  ) %>% \n  # connector = list(line = list(color= \"rgb(63, 63, 63)\"))) %>%\n  layout(title = str_glue(\"{ticker_for_title} Income statement 2019\"),\n        xaxis = list(title = \"\", tickfont = \"16\", ticks = \"outside\"),\n        yaxis = list(title = \"\",\n                     tickprefix = \"$\"),\n        autosize = TRUE,\n        showlegend = TRUE)\n}\n\nNow we pass the aapl_2019_annual_is data frame to the function.\n\n\nincome_statement_waterfall_charter(aapl_2019_annual_is, \"Apple\")\n\n{\"x\":{\"visdat\":{\"11ef4e7612d7\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"11ef4e7612d7\",\"attrs\":{\"11ef4e7612d7\":{\"measure\":{},\"x\":{},\"textposition\":\"outside\",\"y\":{},\"text\":{},\"hoverinfo\":\"text\",\"showlegend\":false,\"name\":\"Income Statement\",\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"waterfall\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"title\":\"Apple Income statement 2019\",\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"\",\"tickfont\":\"16\",\"ticks\":\"outside\",\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"revenue\",\"cogs\",\"grossProfit\",\"rnd\",\"sga\",\"opinc\",\"intexp\",\"ebt\",\"taxExp\",\"netinc\"]},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"\",\"tickprefix\":\"$\"},\"autosize\":true,\"showlegend\":true,\"hovermode\":\"closest\"},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"measure\":[\"relative\",\"relative\",\"total\",\"relative\",\"relative\",\"total\",\"relative\",\"total\",\"relative\",\"total\"],\"x\":[\"revenue\",\"cogs\",\"grossProfit\",\"rnd\",\"sga\",\"opinc\",\"intexp\",\"ebt\",\"taxExp\",\"netinc\"],\"textposition\":[\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\"],\"y\":[260174000000,-161782000000,98392000000,-16217000000,-18245000000,63930000000,-0,65737000000,-10481000000,55256000000],\"text\":[\"Revenue<br />$260.2B\",\"Cost of Goods Sold<br />$-161.8B\",\"Gross Profit<br />$98.4B\",\"Research & Development<br />$-16.2B\",\"Selling, General & Administrative<br />$-18.2B\",\"Operating Income<br />$63.9B\",\"Interest Expense<br />$0.0\",\"Earnings before tax<br />$65.7B\",\"Tax Expense<br />$-10.5B\",\"Net Income<br />$55.3B\"],\"hoverinfo\":[\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\"],\"showlegend\":false,\"name\":\"Income Statement\",\"type\":\"waterfall\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\nNote that we actually called our cogs_get_funs() function inside that visualizer function. We can call functions inside of other functions.\nLet’s say we like that chart of Apple’s Income Statement and want to replicate it for another ticker, MSFT. We can wrap the bottom to top, data import to visualization, in one function that takes one parameter, a ticker.\n\n\noptions(width = 60)\nticker_to_waterfall_funs <- function(ticker){\n  GET(\n  url = str_glue(\n\"https://api.tiingo.com/tiingo/fundamentals/{ticker}/statements?format=csv&startDate=2018-01-01&endDate=2020-01-31&token={api_key}\"\n  )) %>%\n  content(as = \"parsed\")  %>% \n  left_join(definitions) %>% \n  filter(statementType == \"incomeStatement\",\n         year == 2019,\n         quarter == 0) %>% \n  income_statement_waterfall_charter(ticker_for_title = ticker)\n}\n\nticker_to_waterfall_funs(\"MSFT\")\n\n{\"x\":{\"visdat\":{\"11ef5778864a\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"11ef5778864a\",\"attrs\":{\"11ef5778864a\":{\"measure\":{},\"x\":{},\"textposition\":\"outside\",\"y\":{},\"text\":{},\"hoverinfo\":\"text\",\"showlegend\":false,\"name\":\"Income Statement\",\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"waterfall\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"title\":\"MSFT Income statement 2019\",\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"\",\"tickfont\":\"16\",\"ticks\":\"outside\",\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"revenue\",\"cogs\",\"grossProfit\",\"rnd\",\"sga\",\"opinc\",\"intexp\",\"ebt\",\"taxExp\",\"netinc\"]},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"\",\"tickprefix\":\"$\"},\"autosize\":true,\"showlegend\":true,\"hovermode\":\"closest\"},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"measure\":[\"relative\",\"relative\",\"total\",\"relative\",\"relative\",\"total\",\"relative\",\"total\",\"relative\",\"total\"],\"x\":[\"revenue\",\"cogs\",\"grossProfit\",\"rnd\",\"sga\",\"opinc\",\"intexp\",\"ebt\",\"taxExp\",\"netinc\"],\"textposition\":[\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\",\"outside\"],\"y\":[125843000000,-42910000000,82933000000,-16876000000,-23098000000,42959000000,-0,43688000000,-4448000000,39240000000],\"text\":[\"Revenue<br />$125.8B\",\"Cost of Goods Sold<br />$-42.9B\",\"Gross Profit<br />$82.9B\",\"Research & Development<br />$-16.9B\",\"Selling, General & Administrative<br />$-23.1B\",\"Operating Income<br />$43.0B\",\"Interest Expense<br />$0.0\",\"Earnings before tax<br />$43.7B\",\"Tax Expense<br />$-4.4B\",\"Net Income<br />$39.2B\"],\"hoverinfo\":[\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\",\"text\"],\"showlegend\":false,\"name\":\"Income Statement\",\"type\":\"waterfall\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}\n\n\n",
    "preview": "posts/2020-08-18-quanta-versus-funda-mental/q-f.png",
    "last_modified": "2020-09-01T17:19:58-04:00",
    "input_file": {},
    "preview_width": 700,
    "preview_height": 450
  },
  {
    "path": "posts/2020-08-19-a-brief-aside-on-apis/",
    "title": "A Brief Aside on API's",
    "description": "A quick primer on using API's, why they are important and why we use the Tiingo for fundamental data.",
    "author": [
      {
        "name": "Jonathan K. Regenstein",
        "url": "https://fintech.gatech.edu/#/people"
      },
      {
        "name": "Sudheer Chava",
        "url": "https://fintech.gatech.edu/#/people"
      }
    ],
    "date": "2020-08-18",
    "categories": [
      "quantamental",
      "api's"
    ],
    "contents": "\nTable of Contents\nOn APIs\nR and APIs\nThe Tiingo API\nTiingo API documentationAn Example\n\nOn APIs\nBefore we plow on, let’s unpack that term API: it stands for Application Programming Interface. It is a set of rules for how software systems should interact with each other. Right now, we are using R the programming language + RStudio the IDE as one piece of software.\nSomewhere in the land of servers a data provider is storing data in a database, and that’s another software system. An API is the set of rules for how our RStudio software interacts with the database software so that we can import the data from the database. One type of API is a REST API, and that’s the type we’ll be focusing on today and in future articles.\nREST stands for REpresentational State Transfer. What the heck does that mean for us? It means when someone tries to get information from the API (that someone is called a client in the API world, so we’re the client), the server will transfer a representation of the state of the information.\nWait, isn’t the server just transferring the data to us when we ask for it? Not really, the original data stays on the server and maybe the data provider has put all sorts of labels on that data, but we don’t get those labels, we just get what the provider wants to give us.\nAn analogy might be: we go to the registrar of our university and request a copy of our transcripts. The university makes a photocopy of our transcript and gives it to us. But the university keeps the original, and it keeps whatever private stuff has been written about us that isn’t supposed to be shared. We haven’t gotten our actual full transcript, we’ve gotten a represenation of the state of that information. If we complete more courses, the state of the information will change. If the copy that’s given to us has certain pieces missing or that have become blurry, that’s a problem with the API. Possibly it’s also a problem with the underlying, raw data.\nThere can be slow APIs and fast APIs, just as a university can have a very fast system for retrieving transcripts or a very slow system. An API might limit us to, say 1000 requests per minute. Indeed, the owner of the API can construct whatever rules are desired, but the balance is between usability, speed, resource constraints and cost. That’s why when we pay for access to data we are supposed to be paying for faster, more reliable access to data. When an API is free, it comes with constraints. As we’ll cover later, many APIs require us to get a token and our access speed and daily allowances are tied to that token.\nR and APIs\nThe R package we will use to access APIs is the httr (pronounced “hitter”) package.\nFor an introduction to accessing APIs via R code and the httr package, see this vignette.\nThe main function we’ll use is the GET() function, since we are going to be getting data from APIs.\nThe Tiingo API\nLet’s get to the actual API that we’ll be using for many our posts and the book that is work in progess: the Tiingo API, which can be found here: https://api.tiingo.com/. As with most APIs, to access that end point, you will need to sign up and let the service send you an API key.\nWhen you click the link above, you should see a place to sign up in the upper righthand corner:\n\nGo through the steps and check your email for an API key, sometimes called your API token. You will need that token to replicate the code in this project.\nTiingo API documentation\nMost APIs that we wish to access will have documentation to explain how we use the API and retrieve stuff.\nThe Tiingo documentation is available https://api.tiingo.com/documentation/fundamentals. It’s a good idea to have a look at that documentation. Not only will it give us instructions on how to import data, it might also alert us to data we didn’t know existed. In this case, I did not know that tiingo made daily data on PE Ratios and Market Capitalizations available until reading the documentation. Often times the API documentation will have examples that we can copy/paste and then edit to suit our use case. Those are good days.\nAn Example\nWe will cover this more extensively in other posts, but for now here is a quick example of how to import financial statement data for Apple, from “2018-01-01” through “2020-01-31”.\nThe very thing we need to do is set up our API key.\n\n\napi_key <- \"your api key\"\n\nNext we need to figure out what the url string is for Apples financial statements. Here it is:\n“https://api.tiingo.com/tiingo/fundamentals/aapl/statements”.\nWe will need to pass that string, and our API key to the GET() function. We also want to specify the format as a CSV, using format=csv, and the start and end dates using startDate=2018-01-01&endDate=2020-01-31.\nLastly, we need to append our API key to the string, but remember, we saved our key as a variable called api_key, so we can append that variable instead of the actual key. That way, others can’t see our key if we deliver our code to them.\nHere is the final composition of the string to be passed to GET().\n\n\nstr_glue(\n\"https://api.tiingo.com/tiingo/fundamentals/aapl/statements?format=csv&startDate=2018-01-01&endDate=2020-01-31&token={api_key}\"\n)\n\nWe told str_glue() that api_key is a separate variable by using the curly braces, {api_key}.\nNow we can pass that glued string to GET().\n\n\n  GET(\n  url = str_glue(\n    \"https://api.tiingo.com/tiingo/fundamentals/aapl/statements?format=csv&startDate=2018-01-01&endDate=2020-01-31&token={api_key}\"\n  ))\n\nResponse [https://api.tiingo.com/tiingo/fundamentals/aapl/statements?format=csv&startDate=2018-01-01&endDate=2020-01-31&token=97d26898fe27141ef524c1fa3ab0d3f0c3c59b09]\n  Date: 2020-08-20 17:15\n  Status: 200\n  Content-Type: text/csv\n  Size: 38.3 kB\ndate,year,quarter,statementType,dataCode,value\n2019-12-28,2020,1,incomeStatement,eps,5.04\n2019-12-28,2020,1,incomeStatement,netIncDiscOps,0.0\n2019-12-28,2020,1,balanceSheet,equity,89531000000.0\n2019-12-28,2020,1,cashFlow,sbcomp,1710000000.0\n2019-12-28,2020,1,cashFlow,depamor,2816000000.0\n2019-12-28,2020,1,incomeStatement,sga,5197000000.0\n2019-12-28,2020,1,cashFlow,investmentsAcqDisposals,-10473000000.0\n2019-12-28,2020,1,balanceSheet,ppeq,37031000000.0\n2019-12-28,2020,1,balanceSheet,assetsNonCurrent,177387000000.0\n...\n\nHave a look at the results. We were successful in importing the data, but it’s not in great shape.\nLet’s add one more line of code that can help clean up API calls, the magical content(as = \"parsed\").\n\n\n GET(\n  url = str_glue(\n    \"https://api.tiingo.com/tiingo/fundamentals/aapl/statements?format=csv&startDate=2018-01-01&endDate=2020-01-31&token={api_key}\"\n  )) %>% \n  content(as = \"parsed\") %>% \n  head()\n\n# A tibble: 6 x 6\n  date        year quarter statementType   dataCode        value\n  <date>     <dbl>   <dbl> <chr>           <chr>           <dbl>\n1 2019-12-28  2020       1 incomeStatement eps           5.04e 0\n2 2019-12-28  2020       1 incomeStatement netIncDiscOps 0.     \n3 2019-12-28  2020       1 balanceSheet    equity        8.95e10\n4 2019-12-28  2020       1 cashFlow        sbcomp        1.71e 9\n5 2019-12-28  2020       1 cashFlow        depamor       2.82e 9\n6 2019-12-28  2020       1 incomeStatement sga           5.20e 9\n\nMuch better, we now have fundamental data for Apple in a nice tibble format. We have gone from raw data, sitting in Tiingo’s databases, accessed via an API call and GET() to a nicely structured data frame.\n\n\n",
    "preview": "posts/2020-08-19-a-brief-aside-on-apis/api-image.png",
    "last_modified": "2020-08-20T13:15:18-04:00",
    "input_file": {},
    "preview_width": 1192,
    "preview_height": 1304
  }
]
